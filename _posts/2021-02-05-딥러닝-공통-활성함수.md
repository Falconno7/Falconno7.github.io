---
title: "활성함수 (ReLU, sigmoid, tanh, leakyReLU)"
excerpt: "딥러닝에서 사용되는 활성함수의 설명과 장단점"
categories:
    - 딥러닝
    - 공통
tags:
    - 활성함수
    - ReLU
    - sigmoid
    - tanh
    -leakyReLU
toc: true
toc_sticky: true
use_math: true
---

## 1. Sigmoid<br/>
$$ y = \frac{1}{1+exp(-x)}$$<br/>
<br/>

### 1. 시그모이드 함수 특징
1. 비선형 함수.
    1. 비선형 함수는 문자 그대로 '선형이 아닌'함수 입니다. 즉, 직선 1개로 그릴 수 없는 함수를 그릴 수 없는 함수를 말합니다.<br/>
    2. 신경망에서는 활성함수로 비선형함수를 사용해야 합니다. 예를 들어 h(x) = cx를 활성함수로 사용한 3층 네트워크를 떠올려보세요. 이를 식으로 나타내면 $y(x) = h(h(h(x)))$가 됩니다. 이 계산은 $y(x) = ax$와 똑같은 식입니다. $a = c<sup>3</sup>라고만 쓰면 되는 것이죠. 그래서 층을 쌓는 혜택을 얻고 싶다면 활성화 함수로는 반드시 비선형 함수를 사용해야 합니다.<br/>
2. Vanishing Gradient 문제 원인이 되는 함수 입니다. sigmoid는 0 ~ 1사이의 값을 가지기 때문에, 딥러닝의 깊이가 깊어질 수록 역전파의 갱신값은 점점 작아져서 소실되게 됩니다. 또한, sigmoid 자체의 계산량이 크기 때문에 학습시간도 오래걸린다는 단점이 있습니다. 보통은 이 문제를 해소하기 위해 ReLU함수를 대신 사용합니다.

### 2. 설명
1. "칵스"라는 사람이 sigmoid함수를 만들었습니다.

2. sigmoid 함수는 기본적으로 odds비에서 로그를 취해준 logits에서 파생된 함수입니다. odds비는 사건의 성공확률 / 실패확률을 나타내는 수식이며, 식은 y = "성공확률" 일 때, $$\frac{y}{1-y}$$
로 나타냅니다.
3. odds비를 사용하지 않고, 로그를 취해 sigmoid함수를 취하는 이유는 활성함수의 출력값이 0 ~ 1사이가 되어야 하기 때문입니다. odds비는 
$$ odds = \frac{y}{1-y}$$ 
$$ if:y = 1 일 때, answer = \infin $$
$$ elif : y = 0 일 때, answer = 0$$
이 되어버립니다.
4. 출력값이 0 ~ 1사이가 되어야 하는 이유는 다음과 같습니다. odds는 사건확률 / 사건이 일어나지 않을 확률 이기 때문에 1개의 사건이 일어나지 않았을 때의 성공의 기대값이라고 생각이 가능합니다. 그렇기 때문에, odds가 4 즉 4/1일 때, 4번의 사건이 일어나면 1번은 반대에 해당하는 즉, 실패사건이 일어나게 됩니다. 만약, y가 1에 가까우면, 무한번 시도해야 1번의 실패가 일어나는 것이어야 하고, y가 0에 수렴하면, -무한번(존재하지 않는 수)를 시도해야 합니다.
5. 이러한 단점을 보완하기 위해 자연로그를 취하게 됩니다. 자연로그 0은 무한대의 값을 가지며, e는 무리수이면서 초월수이기에 자기자신조차 나눠떨어지지 않으며 odds에 자연로그를 취해주기 적합합니다.
6. 우리는 평소, y의 값을 도출하기 위해 y = ax + b와 같은 선형식을 써왔습니다. a를 weight의 첫글자인 w로 대신하고, odds에 log를 취해준 값과 식을 합치게 되면, 다음과 같은 수식이 탄생합니다. 
$$ ln(\frac{y}{1-y}) = wx + b$$

### 3. 증명
1. 위에서 설명한 $ ln(\frac{y}{1-y}) = wx + b$을 전개해서, sigmoid함수로 만들어 보겠습니다.
$$
ln(\frac{y}{1-y}) = wx + b
$$
$$
 e<sup>wx+b</sup> = \frac{y}{1-y}
$$
$$
  \frac{1}{e<sup>wx+b</sup>} = \frac{1-y}{y} = \frac{1}{y} - 1
$$
$$
 1 + \frac{1}{e<sup>wx+b</sup>} = \frac{1}{y}
$$
$$
\frac{e<sup>wx+b</sup>}{e<sup>wx+b</sup>} +\frac{1}{e<sup>wx+b</sup>} = \frac{1}{y}
$$
$$
\frac{1 + e<sup>wx+b</sup>}{e<sup>wx+b</sup>} = \frac{1}{y}
$$
$$
\frac{e<sup>wx+b</sup>}{1 + e<sup>wx+b</sup>} = y 
$$
$$
\frac{\frac{1}{e<sup>wx+b</sup>}}{\frac{1}{e<sup>wx+b</sup>}} * \frac{e<sup>wx+b</sup>}{1 + e<sup>wx+b</sup>} = y 
$$
$$
\frac{1}{\frac{1 + e<sup>wx+b</sup>}{e<sup>wx+b</sup>}} = y
$$
$$
\frac{1}{\frac{1}{e<sup>wx+b</sup> + 1}} = y
$$
$$
\frac{1}{1+e<sup>-wx+b</sup>} = y
$$
<br/>
2. 딥러닝에서는 학습을 위해 Back-propagation을 사용합니다. 이 때 sigmoid를 미분하는 과정이 필요하게 되므로, 이번 증명에서 미분까지 진행하도록 하겠습니다. y = wx + b를 편의상 g(x)로 치환하겠습니다.
sigmoid또한, S(x)로 부분적으로 사용하겠습니다.
$$
s(g(x))' = (\frac{1}{1+e<sup>-g(x)</sup>})'
$$
$$
=(1+e<sup>-g(x)<\sup>)<sup>-1</sup>'
$$
$$
=-(1+e<sup>-g(x)</sup>)</sup>-2</sup> * (1+ e<sup>-g(x)</sup>)'
$$
$$
=-(1+e<sup>-g(x)</sup>)<sup>-2</sup> * e<sup>-g(x)</sup> * -1
$$
$$
=\frac{e<sup>-g(x)</sup>}{(1+e<sup>-g(x)</sup>)<sup>2</sup>}
$$
$$
=\frac{1+e<sup>-g(x)</sup>}{(1+e<sup>-g(x)</sup>)<sup>2</sup>}
$$
$$
\frac{1+e<sup>-g(x)</sup>-1}{(1+e<sup>-g(x)</sup>)<sup>2</sup>}
$$
$$
=\frac{1}{(1+e<sup>-g(x)</sup>)} - \frac{1}{1(+e<sup>-g(x)</sup>)<sup>2</sup>}
$$
$$
= \frac{1}{1+e<sup>-g(x)</sup>} * (1 - \frac{1}{1+e<sup>-g(x)</sup>})
$$
$$
=S(g(x)) * (1 - S(g(x)))
$$
---
## 2. ReLU 함수
$$
ReLU(x) = max(0,x) if(x <= 0) = 0, else(x > 0) = x
$$
###1. ReLU 함수 특징
1. Sigmoid 함수와 비교해보면 계산량이 적은 것을 알 수 있습니다.
2. ReLU는 출력값이 우리가 원하는 0 ~ 1사이 값이 아니기 때문에, 맨 마지막 레이어는 Sigmoid 함수를 사용해야 합니다.

---
## 3. leakyReLU 함수
$$
LeakyReLU<sub>&alpha;</sub>
$$
## 2. 알고리즘 설명<br/>

* **재귀(Recursion)이란 ?**<br/>

1. 하나의 함수에서 자기 자신을 다시 호출해 작업을 수행하는 알고리즘.<br/>

2. for문을 통해 똑같이 구현 할 수 있다.<br/>

3. 다양한 알고리즘과 접목해서 사용 가능.<br/>

4. 조합(combination), 순열, 팩토리얼 등을 계산 할 때 유용하게 쓰임.<br/>

* **재귀의 장점**<br/>
1. 짧은 코딩으로 빠르게 구현이 가능.<br/>

* **재귀의 단점**<br/>
1. 재귀적 사고방식이 필요하므로 구현이 어려움. <br/> 
특히, 난이도가 있는 문제에서는 재귀적 사고방식 + 절차적 사고방식이 동시에 필요한 경우가 있습니다. 잘 조합해서 문제를 풀어야 하는데, 이게 생각보다 어렵습니다.<br/>

2. 함수 내부에 결함이 있을 경우 어디서 결함이 생기는지 파악하기가 어렵습니다.<br/>

3. 다른 사람이 코드를 알아보기 어려움.<br/>

4. 3번의 이유 + stack overflow가 일어나기 쉽습니다.<br/>
    1. **stack overflow란?**<br/>
    * 코드 내에서 함수가 호출되면 프로세스 메모리상에 stack이라는 곳에 저장되게 됩니다. 재귀함수는 자신을 여러번 호출하는 작업이기에 stack에 계속해서 싸이게 되는데, stack용량이 적게 제한이 걸린 경우, 저장되지 못합니다. 이 경우를 stack overflow라고 합니다.<br/> 
<br/>
<br/>

* **수학적 귀납법**<br/>
    * 다음과 같은 문장이 성립된다면, 재귀도 성립된다고 볼 수 있습니다.<br/>
    * <설명><br/>
    n = 1, 2, 3 ... , n, n+1 .... , func()가 있다고 가정합니다.<br/>
    func()는 특정 기능을 수행하는 함수라고 정의합니다.<br/> <i>또한, 이해를 돕기위해 우리가 평소에 말하는 동사로 치환하여 생각할 수도 있습니다.</i><br/>
    <strong>func(1)이 가능하다.</strong><br/>
    <strong>func(n)이 수행되면, func(k+1)도 수행이 가능하다.</strong><br/>
    이러한 문장이 성립되면, 재귀적으로 문제를 해결할 수 있다고 생각할 수 있습니다.<br/>
    * <예시><br/>
    1번 도미노가 쓰러진다.<br/>
    K번 도미노가 쓰러지면, K + 1번 도미노도 쓰러진다.<br/><br/>
<hr>
<br/>

## 3. 재귀함수를 구현하는데 주의점<br/>

1. **Base Condition**<br/>
* 재귀함수를 구현함에 있어서 가장 먼저 설정해줘야 할 것은 종료조건(Base Condition)입니다.<br/>
또한, 모든 입력은 Base Condition에 수렴하도록 작성을 해줘야 합니다.<br/>

2. **함수 인자를 명확하게**<br/>
* 함수 인자로 어떤 것을 받고 어디까지 계산한 후 자기 자신에게 넘겨줄 것인지 명확하게 해야 합니다.<br/>

3. **한 함수가 자기 자신을 여러 번 호출하게 되면 비효율적**<br/>
* 다음 피보나치 수열을 예를 들어 보겠습니다.<br/>

```python
def fibo(n):
    if n <= 1 : return 1
    return fibo(n-1) + fibo(n-2)
```  

* 얼핏 보기에는 제대로 구현된 것처럼 보일 수 있습니다.<br/>
그러나, 하나의 함수에서 자기 자신을 2번씩 호출하는 과정에 주목해 보시길 바랍니다. n이 10만 되더라도 말도 안되게 복잡해 지는 것을 알 수 있습니다.<br/>
정확하게는 O($1.1618^n$) 만큼의 시간복잡도를 가지기 때문에 만약 n = 100이 된다면, 일반 컴퓨터로는 20000년 넘게 걸리게 됩니다.<br/>


## 4. 재귀함수 구현 방법(개인적인 순서도?)<br/>
* 들어가기에 앞서서, 제가 소개하는 구현 방법은 모든 문제풀이에 해당하지 않습니다.<br/>
다만, 재귀함수를 구현할 때 느끼는 막막함을 조금이나마 해소할 수 있는 방법을 소개해드리겠습니다.<br/>

1. 첫 시작점(예: n == 1) or Base Condition 일 때 어떻게 return해줄 건지를 먼저 생각해야 합니다.<br/>

2. Base Condition설정이 끝나면, Base Condition에 대한 것은 머리속에서 지우고, n번째일 때(n이 마지막일 때) 어떠한 처리를 해줘야 하는지 대략적으로 적습니다.<br/>

* 이 때 주의해야 할 점은, 습관적으로 n-1번 째와 n+1번째를 생각해버리는 것인데, n-1번째를 생각할 때는 **n-1번째에서 계산된 값** 정도로 생각만 하고 넘어가는 것이 좋습니다. n+1번째 값을 생각할 때는 현재 작성하고 있는 코드의 출력이 최종 출력과 같아지는지에 주의하여 출력하면, 자연스럽게 n+1번째 출력도 맞게 됩니다.<br/>

## 느낀 점<br/>
* 재귀는 이후 나올 백트래킹 등에서도 많이 사용되고, 문자열 처리에서도 사용되는 경우가 많습니다. 이 포스트도 앞으로 알고리즘을 더욱 공부해 가면서 계속해서 수정할 예정입니다.<br/>

## 추천 문제<br/>
* BOJ 1629 곱셈  <br/>
* BOJ 11729 하노이 탑 이동 순서  <br/>
* BOJ 1074 Z  <br/>